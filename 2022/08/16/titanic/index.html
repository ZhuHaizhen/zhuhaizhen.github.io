<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>泰坦尼克生存预测 | Haizhen's Blog</title><meta name="description" content="数据来自Titanic - Machine Learning from Disaster 读取数据1234567import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as snsimport warningswarnings.filterwarnings(&#39;ignore&#39;)sns.set"><meta name="keywords" content="machine learning,Kaggle"><meta name="author" content="Zhu Haizhen,zhuhaizhen1024@163.com"><meta name="copyright" content="Zhu Haizhen"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/image/favicon.png"><link rel="canonical" href="https://zhuhaizhen.github.io/2022/08/16/titanic/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="泰坦尼克生存预测"><meta property="og:url" content="https://zhuhaizhen.github.io/2022/08/16/titanic/"><meta property="og:site_name" content="Haizhen's Blog"><meta property="og:description" content="数据来自Titanic - Machine Learning from Disaster 读取数据1234567import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as snsimport warningswarnings.filterwarnings(&#39;ignore&#39;)sns.set"><meta property="og:image" content="https://s1.ax1x.com/2022/04/02/qo9ZW9.jpg"><meta property="article:published_time" content="2022-08-16T02:23:29.000Z"><meta property="article:modified_time" content="2022-08-17T12:45:57.723Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="prev" title="单细胞转录组基础分析" href="https://zhuhaizhen.github.io/2022/08/25/seurat/"><link rel="next" title="复杂流程图绘制" href="https://zhuhaizhen.github.io/2022/06/29/flow-chart/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.js" defer></script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6b1c40d9cb0aeba42b229c550f73967b";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"ULAMU2VKLC","apiKey":"074084189662d00e3b579aef488f16a5","indexName":"hexo-blog","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: {"languages":{"author":"作者: Zhu Haizhen","link":"链接: ","source":"来源: Haizhen's Blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true
  }</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/image/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">36</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">38</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">6</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/collection/"><i class="fa-fw fas fa-paw"></i><span> 随手记</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fas fa-comments"></i><span> 留言板</span></a></div></div></div></div><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#读取数据"><span class="toc-number">1.</span> <span class="toc-text">读取数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#EDA"><span class="toc-number">2.</span> <span class="toc-text">EDA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#将训练集和测试集合并进行数据清洗"><span class="toc-number">3.</span> <span class="toc-text">将训练集和测试集合并进行数据清洗</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#特征工程"><span class="toc-number">4.</span> <span class="toc-text">特征工程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#训练模型"><span class="toc-number">5.</span> <span class="toc-text">训练模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#随机森林"><span class="toc-number">5.1.</span> <span class="toc-text">随机森林</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#逻辑回归"><span class="toc-number">5.2.</span> <span class="toc-text">逻辑回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#支持向量机"><span class="toc-number">5.3.</span> <span class="toc-text">支持向量机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#XGBoost"><span class="toc-number">5.4.</span> <span class="toc-text">XGBoost</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#模型融合"><span class="toc-number">6.</span> <span class="toc-text">模型融合</span></a></li></ol></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://s1.ax1x.com/2022/04/02/qo9ZW9.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Haizhen's Blog</a></span><span class="pull-right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/collection/"><i class="fa-fw fas fa-paw"></i><span> 随手记</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fas fa-comments"></i><span> 留言板</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">泰坦尼克生存预测</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2022-08-16 10:23:29"><i class="far fa-calendar-alt fa-fw"></i> 发表于 2022-08-16</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2022-08-17 20:45:57"><i class="fas fa-history fa-fw"></i> 更新于 2022-08-17</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/%E5%AD%A6%E4%BB%A5%E8%87%B4%E7%94%A8/">学以致用</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta__icon"></i><span>字数总计:</span><span class="word-count">2k</span><span class="post-meta__separator">|</span><i class="far fa-clock fa-fw post-meta__icon"></i><span>阅读时长: 11 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="far fa-eye fa-fw post-meta__icon"></i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"><span class="post-meta__separator">|</span><i class="far fa-comments fa-fw post-meta__icon"></i><span>评论数:</span><a href="/2022/08/16/titanic/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count comment-count" data-xid="/2022/08/16/titanic/" itemprop="commentCount"></span></a></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p>数据来自<a href="https://www.kaggle.com/competitions/titanic" target="_blank" rel="noopener">Titanic - Machine Learning from Disaster</a></p>
<h2 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line">sns.set(style=<span class="string">'whitegrid'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train = pd.read_csv(<span class="string">'../data/train.csv'</span>, index_col=<span class="string">'PassengerId'</span>)</span><br><span class="line">train.head()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBGJSJ.jpg" alt=""></p>
<h2 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 'Pclass'与生存的关系</span></span><br><span class="line">sns.barplot(x=<span class="string">'Pclass'</span>, y=<span class="string">'Survived'</span>, data=train)</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBeq3V.jpg" alt=""><br>客舱等级越高，生存率越高</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 'Sex'与生存率关系</span></span><br><span class="line">sns.barplot(x=<span class="string">'Sex'</span>, y=<span class="string">'Survived'</span>, data=train)</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBmu4I.jpg" alt=""><br>女性生存率远高于男性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 'Age'与生存率关系</span></span><br><span class="line">age_kde = sns.FacetGrid(train, hue=<span class="string">'Survived'</span>, aspect=<span class="number">3</span>)</span><br><span class="line">age_kde.map(sns.kdeplot, <span class="string">'Age'</span>, shade=<span class="literal">True</span>)</span><br><span class="line">age_kde.set(xlim=(<span class="number">0</span>, train[<span class="string">'Age'</span>].max()))</span><br><span class="line">age_kde.add_legend()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBmdCq.jpg" alt=""><br>10岁以下儿童生存的概率高于死亡</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 'SibSp'与生存率的关系</span></span><br><span class="line">sns.barplot(x=<span class="string">'SibSp'</span>, y=<span class="string">'Survived'</span>, data=train)</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBmHVH.jpg" alt=""><br>同辈数量居中时生存率高</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 'Parch'与生存率关系父母或子女数量适中时生存率高</span></span><br><span class="line">sns.barplot(x=<span class="string">'Parch'</span>, y=<span class="string">'Survived'</span>, data=train)</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBmzM8.jpg" alt=""><br>父母或子女数量适中时生存率高</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 'Fare'与生存率关系</span></span><br><span class="line">fare_kde = sns.FacetGrid(train, hue=<span class="string">'Survived'</span>, aspect=<span class="number">3</span>)</span><br><span class="line">fare_kde.map(sns.kdeplot, <span class="string">'Fare'</span>, shade=<span class="literal">True</span>)</span><br><span class="line">fare_kde.set(xlim=(<span class="number">0</span>, train[<span class="string">'Fare'</span>].max()))</span><br><span class="line">fare_kde.add_legend()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBnnLF.jpg" alt=""><br>票价较高时生存的概率大于死亡<br><code>Fare</code>的分布是偏斜的，需要进行对数处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 'Embarked'与生存率关系</span></span><br><span class="line">sns.barplot(x=<span class="string">'Embarked'</span>, y=<span class="string">'Survived'</span>, data=train)</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBuefI.jpg" alt=""></p>
<h2 id="将训练集和测试集合并进行数据清洗"><a href="#将训练集和测试集合并进行数据清洗" class="headerlink" title="将训练集和测试集合并进行数据清洗"></a>将训练集和测试集合并进行数据清洗</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test = pd.read_csv(<span class="string">'../data/test.csv'</span>, index_col=<span class="string">'PassengerId'</span>)</span><br><span class="line">test.head()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBGmyn.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">full = train.drop(<span class="string">'Survived'</span>, axis=<span class="number">1</span>).append(test)</span><br><span class="line">full.shape</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">full.describe()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBuyN9.jpg" alt=""><br>没有明显的异常值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">full.isnull().sum()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBuWjK.jpg" alt=""><br><code>Age</code>, <code>Fare</code>, <code>Cabin</code>, <code>Embarked</code>有缺失值，需要填补</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 'Cabin'缺失值过多，将缺失值作为单独的一类</span></span><br><span class="line">full[<span class="string">'Cabin'</span>] = full[<span class="string">'Cabin'</span>].fillna(<span class="string">'Unknown'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">full[<span class="string">'Embarked'</span>].value_counts()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBuq3t.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用众数填补'Embarked'</span></span><br><span class="line">full[<span class="string">'Embarked'</span>] = full[<span class="string">'Embarked'</span>].fillna(<span class="string">'S'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">full[full[<span class="string">'Fare'</span>].isnull()]</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBuvDS.jpg" alt="">  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用相同条件下的'Fare'的均值填补缺失值</span></span><br><span class="line">full[<span class="string">'Fare'</span>] = full[<span class="string">'Fare'</span>].fillna(full[(full[<span class="string">'Pclass'</span>] == <span class="number">3</span>) &amp; (full[<span class="string">'Embarked'</span>] == <span class="string">'S'</span>)][<span class="string">'Fare'</span>].mean())</span><br></pre></td></tr></table></figure>
<p>用随机森林填补<code>Age</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">age_use = full[[<span class="string">'Pclass'</span>, <span class="string">'Sex'</span>, <span class="string">'Age'</span>, <span class="string">'SibSp'</span>, <span class="string">'Parch'</span>, <span class="string">'Fare'</span>, <span class="string">'Embarked'</span>]]</span><br><span class="line">age_train = age_use[~age_use[<span class="string">'Age'</span>].isnull()]</span><br><span class="line">age_test = age_use[age_use[<span class="string">'Age'</span>].isnull()]</span><br><span class="line">age_y = age_train[<span class="string">'Age'</span>]</span><br><span class="line">age_train = age_train.drop(<span class="string">'Age'</span>, axis=<span class="number">1</span>)</span><br><span class="line">age_test = age_test.drop(<span class="string">'Age'</span>, axis=<span class="number">1</span>)</span><br><span class="line">age_X_train = pd.get_dummies(age_train) <span class="comment"># 独热编码</span></span><br><span class="line">age_X_test = pd.get_dummies(age_test)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line">rfr = RandomForestRegressor(random_state=<span class="number">42</span>, n_estimators=<span class="number">100</span>)</span><br><span class="line">rfr.fit(age_X_train, age_y)</span><br><span class="line">rfr.score(age_X_train, age_y) <span class="comment"># 0.686420545226768</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">age_pred = rfr.predict(age_X_test)</span><br><span class="line">full.loc[full[<span class="string">'Age'</span>].isnull(), <span class="string">'Age'</span>] = age_pred</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">full.isnull().sum()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBKOi9.jpg" alt=""></p>
<h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">full[<span class="string">'logFare'</span>] = full[<span class="string">'Fare'</span>].apply(<span class="keyword">lambda</span> x: np.log(x) <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">sns.kdeplot(full[<span class="string">'logFare'</span>])</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBKzM6.jpg" alt=""><br>从姓名中提取Title</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">full[<span class="string">'Title'</span>] = full[<span class="string">'Name'</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">','</span>)[<span class="number">1</span>].split(<span class="string">'.'</span>)[<span class="number">0</span>].strip())</span><br><span class="line">full[<span class="string">'Title'</span>].value_counts()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBMeQP.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">full.loc[~full[<span class="string">'Title'</span>].isin([<span class="string">'Mr'</span>, <span class="string">'Miss'</span>, <span class="string">'Mrs'</span>, <span class="string">'Master'</span>]), <span class="string">'Title'</span>] = <span class="string">'Other'</span></span><br><span class="line">full[<span class="string">'Title'</span>].value_counts()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBMMdg.jpg" alt=""><br>将<code>SibSp</code>和<code>Parch</code>合并，创造新特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">full[<span class="string">'FamilySize'</span>] = full[<span class="string">'SibSp'</span>] + full[<span class="string">'Parch'</span>] + <span class="number">1</span></span><br><span class="line">full[<span class="string">'IsAlone'</span>] = full[<span class="string">'FamilySize'</span>].apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x == <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>根据年龄创造是否为儿童的特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">full[<span class="string">'IsChild'</span>] = full[<span class="string">'Age'</span>].apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &lt; <span class="number">10</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>统计相同票号的情况，创造特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">full[<span class="string">'Ticket'</span>].value_counts()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBMaeU.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tic_cnt_dict = &#123;&#125;</span><br><span class="line">tic_cnt_dict = full[<span class="string">'Ticket'</span>].value_counts()</span><br><span class="line">full[<span class="string">'TicketCnt'</span>] = full[<span class="string">'Ticket'</span>].map(tic_cnt_dict)</span><br></pre></td></tr></table></figure>
<p>删除无用的特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">full_use = full.drop([<span class="string">'Name'</span>, <span class="string">'Ticket'</span>, <span class="string">'Fare'</span>], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>独热编码，重新划分训练集和测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">full_dum = pd.get_dummies(full_use)</span><br><span class="line">X_dum_train = full_dum[full_dum.index.isin(train.index.tolist())]</span><br><span class="line">X_dum_test = full_dum[full_dum.index.isin(test.index.tolist())]</span><br><span class="line">X_dum_train.shape, X_dum_test.shape <span class="comment"># ((891, 206), (418, 206))</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_train_use = train[<span class="string">'Survived'</span>].reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>互信息法筛选特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> mutual_info_classif</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mic = mutual_info_classif(X_dum_train, y_train_use, random_state=<span class="number">42</span>)</span><br><span class="line">k = mic.shape[<span class="number">0</span>] - sum(mic &lt;= <span class="number">0</span>)</span><br><span class="line">kmic = SelectKBest(mutual_info_classif, k).fit(X_dum_train, y_train_use)</span><br><span class="line">X_train_mic = kmic.transform(X_dum_train)</span><br><span class="line">X_train_mic.shape <span class="comment"># (891, 111)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_test_mic = kmic.transform(X_dum_test)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.savetxt(<span class="string">'../data/X_train_mic.csv'</span>, X_train_mic, delimiter=<span class="string">','</span>)</span><br><span class="line">np.savetxt(<span class="string">'../data/X_test_mic.csv'</span>, X_test_mic, delimiter=<span class="string">','</span>)</span><br></pre></td></tr></table></figure>
<h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><p>常用分类模型：</p>
<ul>
<li>逻辑回归</li>
<li>随机森林</li>
<li>支持向量机</li>
<li>XGBoost</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, GridSearchCV</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X_train_mic, y_train_use, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>
<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rf_param = &#123;<span class="string">'criterion'</span>: [<span class="string">'gini'</span>, <span class="string">'entropy'</span>]&#125;</span><br><span class="line">rf = RandomForestClassifier(random_state=<span class="number">42</span>, n_estimators=<span class="number">100</span>)</span><br><span class="line">rf_cv = GridSearchCV(rf, rf_param, cv=<span class="number">5</span>)</span><br><span class="line">rf_cv.fit(X_train, y_train)</span><br><span class="line">rf_cv.score(X_test, y_test) <span class="comment"># 0.8212290502793296</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rf_cv.best_params_ <span class="comment"># &#123;'criterion': 'entropy'&#125;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">rf_score = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>, <span class="number">11</span>):</span><br><span class="line">    rf = RandomForestClassifier(criterion=<span class="string">'entropy'</span>, random_state=<span class="number">42</span>, n_estimators=<span class="number">100</span>, max_depth=i)</span><br><span class="line">    rf.fit(X_train, y_train)</span><br><span class="line">    rf_score.append(rf.score(X_test, y_test))</span><br><span class="line"></span><br><span class="line">plt.plot(range(<span class="number">5</span>, <span class="number">11</span>), rf_score)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBQDHS.jpg" alt=""><br>max_depth=6</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">rf_score = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">40</span>, <span class="number">80</span>, <span class="number">5</span>):</span><br><span class="line">    rf = RandomForestClassifier(criterion=<span class="string">'entropy'</span>, max_depth=<span class="number">6</span>, random_state=<span class="number">42</span>, n_estimators=i)</span><br><span class="line">    rf.fit(X_train, y_train)</span><br><span class="line">    rf_score.append(rf.score(X_test, y_test))</span><br><span class="line"></span><br><span class="line">plt.plot(range(<span class="number">40</span>, <span class="number">80</span>, <span class="number">5</span>), rf_score)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBQhuV.jpg" alt=""><br>n_estimators=60</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rf = RandomForestClassifier(criterion=<span class="string">'entropy'</span>, n_estimators=<span class="number">60</span>, max_depth=<span class="number">6</span>, random_state=<span class="number">42</span>)</span><br><span class="line">rf.fit(X_train_mic, y_train_use)</span><br><span class="line">rf_pred = rf.predict(X_test_mic)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rf_sub = pd.DataFrame(&#123;<span class="string">'PassengerId'</span>: test.index.tolist(), <span class="string">'Survived'</span>: rf_pred&#125;)</span><br><span class="line">rf_sub.to_csv(<span class="string">'../result/rf.csv'</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lr_param = &#123;<span class="string">'solver'</span>: [<span class="string">'liblinear'</span>, <span class="string">'lbfgs'</span>, <span class="string">'sag'</span>]&#125;</span><br><span class="line">lr = LogisticRegression(random_state=<span class="number">42</span>)</span><br><span class="line">lr_cv = GridSearchCV(lr, lr_param, cv=<span class="number">5</span>)</span><br><span class="line">lr_cv.fit(X_train, y_train)</span><br><span class="line">lr_cv.score(X_test, y_test) <span class="comment"># 0.8212290502793296</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr_cv.best_params_ <span class="comment"># &#123;'solver': 'lbfgs'&#125;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">lr_score = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">15</span>, <span class="number">21</span>):</span><br><span class="line">    lr = LogisticRegression(random_state=<span class="number">42</span>, solver=<span class="string">'lbfgs'</span>, max_iter=i)</span><br><span class="line">    lr.fit(X_train, y_train)</span><br><span class="line">    lr_score.append(lr.score(X_test, y_test))</span><br><span class="line"></span><br><span class="line">plt.plot(range(<span class="number">15</span>, <span class="number">21</span>), lr_score)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vBl4xI.jpg" alt=""><br>max_iter=19</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">lr_score = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.linspace(<span class="number">0.001</span>, <span class="number">0.05</span>, <span class="number">20</span>):</span><br><span class="line">    lr = LogisticRegression(random_state=<span class="number">42</span>, solver=<span class="string">'lbfgs'</span>, max_iter=<span class="number">19</span>, C=i)</span><br><span class="line">    lr.fit(X_train, y_train)</span><br><span class="line">    lr_score.append(lr.score(X_test, y_test))</span><br><span class="line"></span><br><span class="line">plt.plot(np.linspace(<span class="number">0.001</span>, <span class="number">0.05</span>, <span class="number">20</span>), lr_score)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vB1pLV.jpg" alt=""><br>C=0.01</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(random_state=<span class="number">42</span>, solver=<span class="string">'lbfgs'</span>, max_iter=<span class="number">19</span>, C=<span class="number">0.01</span>)</span><br><span class="line">lr.fit(X_train_mic, y_train_use)</span><br><span class="line">lr_pred = lr.predict(X_test_mic)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lr_sub = pd.DataFrame(&#123;<span class="string">'PassengerId'</span>: test.index.tolist(), <span class="string">'Survived'</span>: lr_pred&#125;)</span><br><span class="line">lr_sub.to_csv(<span class="string">'../result/lr.csv'</span>, index=Flse)</span><br></pre></td></tr></table></figure>
<h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">svc_param = &#123;<span class="string">'kernel'</span>: [<span class="string">'linear'</span>, <span class="string">'poly'</span>, <span class="string">'rbf'</span>, <span class="string">'sigmoid'</span>]&#125;</span><br><span class="line">svc = SVC(random_state=<span class="number">42</span>)</span><br><span class="line">svc_cv = GridSearchCV(svc, svc_param, cv=<span class="number">5</span>)</span><br><span class="line">svc_cv.fit(X_train, y_train)</span><br><span class="line">svc_cv.score(X_test, y_test) <span class="comment"># 0.8100558659217877</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">svc_cv.best_params_ <span class="comment"># &#123;'kernel': 'linear'&#125;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">svc_score = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.linspace(<span class="number">0.01</span>, <span class="number">0.05</span>, <span class="number">10</span>):</span><br><span class="line">    svc = SVC(random_state=<span class="number">42</span>, kernel=<span class="string">'linear'</span>, C=i)</span><br><span class="line">    svc.fit(X_train, y_train)</span><br><span class="line">    svc_score.append(svc.score(X_test, y_test))</span><br><span class="line"></span><br><span class="line">plt.plot(np.linspace(<span class="number">0.01</span>, <span class="number">0.05</span>, <span class="number">10</span>), svc_score)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vB1dw8.jpg" alt=""><br>C=0.045</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">svc = SVC(random_state=<span class="number">42</span>, kernel=<span class="string">'linear'</span>, C=<span class="number">0.045</span>)</span><br><span class="line">svc.fit(X_train_mic, y_train_use)</span><br><span class="line">svc_pred = svc.predict(X_test_mic)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">svc_sub = pd.DataFrame(&#123;<span class="string">'PassengerId'</span>: test.index.tolist(), <span class="string">'Survived'</span>: svc_pred&#125;)</span><br><span class="line">svc_sub.to_csv(<span class="string">'../result/svc.csv'</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h3 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line">dtrain_mic = xgb.DMatrix(X_train_mic, y_train_use)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">xgb_param = &#123;<span class="string">'silent'</span>: <span class="literal">True</span>, <span class="string">'obj'</span>: <span class="string">'binary:logistic'</span>, <span class="string">'subsample'</span>: <span class="number">0.8</span>, <span class="string">'max_depth'</span>: <span class="number">5</span>,</span><br><span class="line">             <span class="string">'eta'</span>: <span class="number">0.3</span>, <span class="string">'gamma'</span>: <span class="number">0</span>, <span class="string">'lambda'</span>: <span class="number">1</span>, <span class="string">'alpha'</span>: <span class="number">0</span>, <span class="string">'colsample_bytree'</span>: <span class="number">1</span>,</span><br><span class="line">             <span class="string">'colsample_bylevel'</span>: <span class="number">1</span>, <span class="string">'colsample_bynode'</span>: <span class="number">1</span>, <span class="string">'nfold'</span>: <span class="number">5</span>, <span class="string">'n_estimators'</span>: <span class="number">1000</span>,</span><br><span class="line">             <span class="string">'seed'</span>: <span class="number">42</span>&#125;</span><br><span class="line">num_round = <span class="number">200</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xgb.cv(xgb_param, dtrain_mic, num_round, metrics=<span class="string">'auc'</span>, early_stopping_rounds=<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vB1O0K.jpg" alt=""><br>n_estimators=21</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv_param = &#123;<span class="string">'max_depth'</span>: range(<span class="number">2</span>, <span class="number">10</span>, <span class="number">2</span>), <span class="string">'min_child_weight'</span>: range(<span class="number">1</span>, <span class="number">6</span>, <span class="number">2</span>)&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xgb_cv = GridSearchCV(estimator=XGBClassifier(objective=<span class="string">'binary:logistic'</span>, subsample=<span class="number">0.8</span>, learning_rate=<span class="number">0.1</span>, gamma=<span class="number">0</span>, alpha=<span class="number">0</span>, colsample_bytree=<span class="number">1</span>, colsample_bylevel=<span class="number">1</span>, colsample_bynode=<span class="number">1</span>, nfold=<span class="number">5</span>, n_estimators=<span class="number">21</span>, seed=<span class="number">42</span>, silent=<span class="literal">True</span>), param_grid=cv_param, scoring=<span class="string">'roc_auc'</span>, cv=<span class="number">5</span>)</span><br><span class="line">xgb_cv.fit(X_train, y_train)</span><br><span class="line">xgb_cv.score(X_test, y_test) <span class="comment"># 0.8926640926640927</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xgb_cv.best_params_ <span class="comment"># &#123;'max_depth': 8, 'min_child_weight': 3&#125;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv_param = &#123;<span class="string">'max_depth'</span>: [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>], <span class="string">'min_child_weight'</span>: [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xgb_cv = GridSearchCV(estimator=XGBClassifier(objective=<span class="string">'binary:logistic'</span>, subsample=<span class="number">0.8</span>, learning_rate=<span class="number">0.1</span>, gamma=<span class="number">0</span>, alpha=<span class="number">0</span>, colsample_bytree=<span class="number">1</span>, colsample_bylevel=<span class="number">1</span>, colsample_bynode=<span class="number">1</span>, nfold=<span class="number">5</span>, n_estimators=<span class="number">21</span>, seed=<span class="number">42</span>, silent=<span class="literal">True</span>), param_grid=cv_param, scoring=<span class="string">'roc_auc'</span>, cv=<span class="number">5</span>)</span><br><span class="line">xgb_cv.fit(X_train, y_train)</span><br><span class="line">xgb_cv.score(X_test, y_test) <span class="comment"># 0.8926640926640927</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xgb_cv.best_params_ <span class="comment"># &#123;'max_depth': 8, 'min_child_weight': 3&#125;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv_param = &#123;<span class="string">'gamma'</span>: [i/<span class="number">10</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">5</span>)]&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xgb_cv = GridSearchCV(estimator=XGBClassifier(objective=<span class="string">'binary:logistic'</span>, subsample=<span class="number">0.8</span>, learning_rate=<span class="number">0.1</span>, alpha=<span class="number">0</span>, colsample_bytree=<span class="number">1</span>, colsample_bylevel=<span class="number">1</span>, colsample_bynode=<span class="number">1</span>, nfold=<span class="number">5</span>, n_estimators=<span class="number">21</span>, seed=<span class="number">42</span>, max_depth=<span class="number">8</span>, min_child_weight=<span class="number">3</span>), param_grid=cv_param, scoring=<span class="string">'roc_auc'</span>, cv=<span class="number">5</span>)</span><br><span class="line">xgb_cv.fit(X_train, y_train)</span><br><span class="line">xgb_cv.score(X_test, y_test) <span class="comment"># 0.8926640926640927</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xgb_cv.best_params_ <span class="comment"># &#123;'gamma': 0.0&#125;</span></span><br></pre></td></tr></table></figure>
<p>重新调整n_estimators</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">xgb_param = &#123;<span class="string">'obj'</span>: <span class="string">'binary:logistic'</span>, <span class="string">'subsample'</span>: <span class="number">0.8</span>, <span class="string">'max_depth'</span>: <span class="number">8</span>,</span><br><span class="line">             <span class="string">'learning_rate'</span>: <span class="number">0.1</span>, <span class="string">'gamma'</span>: <span class="number">0</span>, <span class="string">'lambda'</span>: <span class="number">1</span>, <span class="string">'alpha'</span>: <span class="number">0</span>, <span class="string">'colsample_bytree'</span>: <span class="number">1</span>,</span><br><span class="line">             <span class="string">'colsample_bylevel'</span>: <span class="number">1</span>, <span class="string">'colsample_bynode'</span>: <span class="number">1</span>, <span class="string">'n_estimators'</span>: <span class="number">1000</span>,</span><br><span class="line">             <span class="string">'min_child_weight'</span>: <span class="number">3</span>, <span class="string">'seed'</span>: <span class="number">42</span>&#125;</span><br><span class="line">num_round = <span class="number">200</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xgb.cv(xgb_param, dtrain_mic, num_round, metrics=<span class="string">'auc'</span>, early_stopping_rounds=<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<p><img src= "/img/loading.gif" data-src="https://s1.ax1x.com/2022/08/17/vB3xbV.jpg" alt=""><br>n_estimators=26</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cv_param = &#123;<span class="string">'subsample'</span>: [i/<span class="number">10</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">10</span>)],</span><br><span class="line">            <span class="string">'colsample_bytree'</span>: [i/<span class="number">10</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">10</span>)]&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xgb_cv = GridSearchCV(estimator=XGBClassifier(objective=<span class="string">'binary:logistic'</span>, subsample=<span class="number">0.8</span>, learning_rate=<span class="number">0.1</span>, alpha=<span class="number">0</span>, gamma=<span class="number">0</span>, colsample_bytree=<span class="number">1</span>, colsample_bylevel=<span class="number">1</span>, colsample_bynode=<span class="number">1</span>, nfold=<span class="number">5</span>, n_estimators=<span class="number">26</span>, seed=<span class="number">42</span>, max_depth=<span class="number">8</span>, min_child_weight=<span class="number">3</span>), param_grid=cv_param, scoring=<span class="string">'roc_auc'</span>, cv=<span class="number">5</span>)</span><br><span class="line">xgb_cv.fit(X_train, y_train)</span><br><span class="line">xgb_cv.score(X_test, y_test) <span class="comment"># 0.8940797940797941</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xgb_cv.best_params_ <span class="comment"># &#123;'colsample_bytree': 0.6, 'subsample': 0.6&#125;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv_param = &#123;<span class="string">'alpha'</span>: [<span class="number">1e-5</span>, <span class="number">1e-2</span>, <span class="number">0</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">100</span>]&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xgb_cv = GridSearchCV(estimator=XGBClassifier(objective=<span class="string">'binary:logistic'</span>, subsample=<span class="number">0.6</span>, learning_rate=<span class="number">0.1</span>, alpha=<span class="number">0</span>, gamma=<span class="number">0</span>, colsample_bytree=<span class="number">0.6</span>, colsample_bylevel=<span class="number">1</span>, colsample_bynode=<span class="number">1</span>, nfold=<span class="number">5</span>, n_estimators=<span class="number">26</span>, seed=<span class="number">42</span>, max_depth=<span class="number">8</span>, min_child_weight=<span class="number">3</span>), param_grid=cv_param, scoring=<span class="string">'roc_auc'</span>, cv=<span class="number">5</span>)</span><br><span class="line">xgb_cv.fit(X_train, y_train)</span><br><span class="line">xgb_cv.score(X_test, y_test) <span class="comment"># 0.8956241956241956</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xgb_cv.best_params_ <span class="comment"># &#123;'alpha': 0.1&#125;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xgbc = XGBClassifier(objective=<span class="string">'binary:logistic'</span>, subsample=<span class="number">0.6</span>, learning_rate=<span class="number">0.1</span>, alpha=<span class="number">0</span>, gamma=<span class="number">0</span>, colsample_bytree=<span class="number">0.6</span>, colsample_bylevel=<span class="number">1</span>, colsample_bynode=<span class="number">1</span>, nfold=<span class="number">5</span>, n_estimators=<span class="number">26</span>, seed=<span class="number">42</span>, max_depth=<span class="number">8</span>, min_child_weight=<span class="number">3</span>)</span><br><span class="line">xgbc.fit(X_train, y_train)</span><br><span class="line">xgbc.score(X_test, y_test) <span class="comment"># 0.8268156424581006</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xgbc.fit(X_train_mic, y_train_use)</span><br><span class="line">xgb_pred = xgbc.predict(X_test_mic)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xgb_sub = pd.DataFrame(&#123;<span class="string">'PassengerId'</span>: test.index.tolist(), <span class="string">'Survived'</span>: xgb_pred&#125;)</span><br><span class="line">xgb_sub.to_csv(<span class="string">'../result/xgb.csv'</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h2 id="模型融合"><a href="#模型融合" class="headerlink" title="模型融合"></a>模型融合</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_oof</span><span class="params">(clf, x_train, y_train, x_test)</span>:</span></span><br><span class="line">    ntrain = x_train.shape[<span class="number">0</span>]</span><br><span class="line">    ntest = x_test.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line">    kf = KFold(n_splits=<span class="number">5</span>, random_state=<span class="number">42</span>).split(x_train)</span><br><span class="line"></span><br><span class="line">    oof_train = np.zeros((ntrain,))</span><br><span class="line">    oof_test = np.zeros((ntest,))</span><br><span class="line">    oof_test_skf = np.empty((<span class="number">5</span>, ntest))  <span class="comment">#NFOLDS行，ntest列的二维array</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, (train_index, test_index) <span class="keyword">in</span> enumerate(kf): <span class="comment">#循环NFOLDS次</span></span><br><span class="line">        x_tr = x_train[train_index]</span><br><span class="line">        y_tr = y_train[train_index]</span><br><span class="line">        x_te = x_train[test_index]</span><br><span class="line">        clf.fit(x_tr, y_tr)</span><br><span class="line">        oof_train[test_index] = clf.predict(x_te)</span><br><span class="line">        oof_test_skf[i, :] = clf.predict(x_test)  <span class="comment">#固定行填充，循环一次，填充一行</span></span><br><span class="line">    oof_test[:] = oof_test_skf.mean(axis=<span class="number">0</span>)  <span class="comment">#axis=0,按列求平均，最后保留一行</span></span><br><span class="line">    <span class="keyword">return</span> oof_train.reshape(<span class="number">-1</span>, <span class="number">1</span>), oof_test.reshape(<span class="number">-1</span>, <span class="number">1</span>)  <span class="comment">#转置，从一行变为一列</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rf_oof_train, rf_oof_test = get_oof(rf, X_train_mic, y_train_use, X_test_mic)</span><br><span class="line">lr_oof_train, lr_oof_test = get_oof(lr, X_train_mic, y_train_use, X_test_mic)</span><br><span class="line">svc_oof_train, svc_oof_test = get_oof(svc, X_train_mic, y_train_use, X_test_mic)</span><br><span class="line">xgb_oof_train, xgb_oof_test = get_oof(xgbc, X_train_mic, y_train_use, X_test_mic)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_l2 = np.hstack([rf_oof_train, lr_oof_train, svc_oof_train, xgb_oof_train])</span><br><span class="line">test_l2 = np.hstack([rf_oof_test, lr_oof_test, svc_oof_test, xgb_oof_test])</span><br><span class="line">X_train_l2, X_test_l2, y_train_l2, y_test_l2 = train_test_split(train_l2, y_train_use, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dt = DecisionTreeClassifier(random_state=<span class="number">42</span>, max_depth=<span class="number">3</span>)</span><br><span class="line">dt.fit(X_train_l2, y_train_l2)</span><br><span class="line">dt.score(X_test_l2, y_test_l2) <span class="comment"># 0.8268156424581006</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">stack_pred = dt.predict(test_l2)</span><br><span class="line">stack_sub = pd.DataFrame(&#123;<span class="string">'PassengerId'</span>: test.index.tolist(), <span class="string">'Survived'</span>: stack_pred&#125;)</span><br><span class="line">stack_sub.to_csv(<span class="string">'../result/stack.csv'</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:zhuhaizhen1024@163.com">Zhu Haizhen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://zhuhaizhen.github.io/2022/08/16/titanic/">https://zhuhaizhen.github.io/2022/08/16/titanic/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://zhuhaizhen.github.io" target="_blank">Haizhen's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/machine-learning/">machine learning</a><a class="post-meta__tags" href="/tags/Kaggle/">Kaggle</a></div><div class="post_share"><div class="social-share" data-image="https://s1.ax1x.com/2022/04/02/qo9ZW9.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><button class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="/image/wechat.jpg" alt="微信" onclick="window.open('/image/wechat.jpg')"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="post-qr-code__img" src="/image/alipay.jpg" alt="支付宝" onclick="window.open('/image/alipay.jpg')"/><div class="post-qr-code__desc">支付宝</div></li></ul></div></button></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/08/25/seurat/"><img class="prev-cover" data-src="https://s1.ax1x.com/2022/04/02/qo9ZW9.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">单细胞转录组基础分析</div></div></a></div><div class="next-post pull-right"><a href="/2022/06/29/flow-chart/"><img class="next-cover" data-src="https://s1.ax1x.com/2022/06/30/julxaD.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">复杂流程图绘制</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/12/09/LP&simplex/" title="线性规划与单纯形算法"><img class="relatedPosts_cover" data-src="https://s1.ax1x.com/2022/04/02/qo9ZW9.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-12-09</div><div class="relatedPosts_title">线性规划与单纯形算法</div></div></a></div><div class="relatedPosts_item"><a href="/2021/01/04/PCA&LDA/" title="PCA和LDA"><img class="relatedPosts_cover" data-src="https://s1.ax1x.com/2022/04/02/qo9QeK.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-01-04</div><div class="relatedPosts_title">PCA和LDA</div></div></a></div><div class="relatedPosts_item"><a href="/2020/12/05/SMO/" title="SMO算法"><img class="relatedPosts_cover" data-src="https://s1.ax1x.com/2022/04/02/qo9Ei4.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-12-05</div><div class="relatedPosts_title">SMO算法</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var requestSetting = function (from,set) {
  var from = from
  var setting = set.split(',').filter(function(item){
  return from.indexOf(item) > -1
  });
  setting = setting.length == 0 ? from :setting;
  return setting
}

var guestInfo = requestSetting(['nick','mail','link'],'昵称,邮箱,网址')
var requiredFields = requestSetting(['nick','mail'],'昵称,邮箱')

window.valine = new Valine({
  el:'#vcomment',
  appId: 'yDcQjFWTIoApJ6qYc7DCVIjO-gzGzoHsz',
  appKey: 'y66ni3n3AtYNrLgaqdJGzAPo',
  placeholder: '请留下你的昵称和邮箱，方便接收回复',
  avatar: 'monsterid',
  meta: guestInfo,
  pageSize: '10',
  lang: 'zh-CN',
  recordIP: false,
  serverURLs: '',
  emojiCDN: '',
  emojiMaps: "",
  enableQQ: false,
  requiredFields: requiredFields
});</script></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Zhu Haizhen</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">君子不器</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><button id="readmode" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" title="设置"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fas fa-comments"></i></a><button class="close" id="mobile-toc-button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script src="/js/third-party/activate-power-mode.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
document.body.addEventListener('input', POWERMODE);
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="/js/third-party/click_heart.js"></script><script src="/js/search/algolia.js"></script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>